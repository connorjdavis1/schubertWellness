geom_smooth()
ggplot(schubertDataClean, aes(start_date, npvi, wellness)) +
geom_rect(aes(NULL, NULL,
xmin=start_date - .5 ,xmax=start_date +.5,
ymin=min(npvi), ymax=max(npvi),
fill=wellness, alpha = 0.5)) +
geom_point() +
geom_smooth()
ggplot(schubertDataClean, aes(start_date, npvi, wellness)) +
geom_rect(aes(NULL, NULL,
xmin=start_date - .5 ,xmax=start_date +.5,
ymin=min(npvi), ymax=max(npvi),
fill=wellness)) +
geom_point() +
geom_smooth()
#it seems there is a difference in at least melodic output
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
annotate(geom = "rect", xmin=start_date - .5 ,xmax=start_date +.5,
ymin=min(degree_entropy), ymax=max(degree_entropy),
fill=wellness)+
) +
#it seems there is a difference in at least melodic output
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
annotate(geom = "rect", xmin=start_date - .5 ,xmax=start_date +.5,
ymin=min(degree_entropy), ymax=max(degree_entropy),
fill=wellness +
) +
fill = wellness +
#it seems there is a difference in at least melodic output
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
annotate(geom = "rect", xmin=start_date - .5 ,xmax=start_date +.5,
ymin=min(degree_entropy), ymax=max(degree_entropy),
fill = wellness) +
geom_point() +
geom_smooth()
#it seems there is a difference in at least melodic output
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
annotate(geom = "rect", xmin=start_date - .5 ,xmax=start_date +.5,
ymin=min(degree_entropy), ymax=max(degree_entropy),
fill = schubertDataClean$wellness) +
geom_point() +
geom_smooth()
#it seems there is a difference in at least melodic output
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
annotate(geom = "rect", xmin=schubertDataClean$start_date - .5 ,xmin=schubertDataClean$start_date +.5,
ymin=min(degree_entropy), ymax=max(degree_entropy),
fill = schubertDataClean$wellness) +
geom_point() +
geom_smooth()
annotate(geom = "rect", xmin=min(schubertDataClean$start_date - .5 , xmax=schubertDataClean$start_date +.5,
#it seems there is a difference in at least melodic output
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
annotate(geom = "rect", xmin=minschubertDataClean$start_date - .5 , xmax=schubertDataClean$start_date +.5,
ymin=min(degree_entropy), ymax=max(degree_entropy),
fill = schubertDataClean$wellness) +
geom_point() +
geom_smooth()
#it seems there is a difference in at least melodic output
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
#it seems there is a difference in at least melodic output
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
annotate(geom = "rect", xmin=minschubertDataClean$start_date - .5 , xmax=schubertDataClean$start_date +.5,
ymin=min(degree_entropy), ymax=max(degree_entropy),
fill = schubertDataClean$wellness, alph = 0.6) +
geom_point() +
geom_smooth()
#it seems there is a difference in at least melodic output
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
annotate(geom = "rect", xmin=min(schubertDataClean$start_date - .5), xmax=max(schubertDataClean$start_date +.5),
ymin=min(degree_entropy), ymax=max(degree_entropy),
fill = schubertDataClean$wellness, alph = 0.6) +
geom_point() +
geom_smooth()
#it seems there is a difference in at least melodic output
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
annotate(geom = "rect", xmin=min(schubertDataClean$start_date - .5), xmax=max(schubertDataClean$start_date +.5),
ymin=min(schubertDataClean$degree_entropy), ymax=max(schubertDataClean$degree_entropy),
fill = schubertDataClean$wellness, alph = 0.6) +
geom_point() +
geom_smooth()
#it seems there is a difference in at least melodic output
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
annotate(geom = "rect", xmin=min(schubertDataClean$start_date - .5), xmax=max(schubertDataClean$start_date +.5),
ymin=min(schubertDataClean$degree_entropy), ymax=max(schubertDataClean$degree_entropy),
fill = schubertDataClean$wellness, alph = 0.6) +
geom_point() +
geom_smooth()
#it seems there is a difference in at least melodic output
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
annotate(geom = "rect", xmin=min(schubertDataClean$start_date - .5), xmax=max(schubertDataClean$start_date +.5),
ymin=min(schubertDataClean$degree_entropy), ymax=max(schubertDataClean$degree_entropy),
fill = "schubertDataClean$wellness", alph = 0.6) +
geom_point() +
geom_smooth()
#it seems there is a difference in at least melodic output
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
annotate(geom = "rect", xmin=min(schubertDataClean$start_date - .5), xmax=max(schubertDataClean$start_date +.5),
ymin=min(schubertDataClean$degree_entropy), ymax=max(schubertDataClean$degree_entropy),
fill = "schubertDataClean$wellness", alpha = 0.6) +
geom_point() +
geom_smooth()
#it seems there is a difference in at least melodic output
tester <- ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness))
tester+
annotate(geom = "rect", xmin=min(schubertDataClean$start_date - .5), xmax=max(schubertDataClean$start_date +.5),
ymin=min(schubertDataClean$degree_entropy), ymax=max(schubertDataClean$degree_entropy),
fill = schubertDataClean$wellness, alpha = 0.6) +
geom_point() +
geom_smooth()
tester+
annotate(geom = "rect", xmin=min(schubertDataClean$start_date - .5), xmax=max(schubertDataClean$start_date +.5),
ymin=min(schubertDataClean$degree_entropy), ymax=max(schubertDataClean$degree_entropy),
alpha = 0.6) +
geom_point() +
geom_smooth()
#use 70% of dataset as training set and 30% as test set
schubertTrain <- schubertDataClean %>%
sample_frac(0.70)
View(schubertTrain)
schubertTest  <- anti_join(schubertDataClean, train, by = 'wellness')
schubertTest  <- anti_join(schubertDataClean, schubertTrain, by = 'wellness')
predict(glmSchubert, schubertTest, type = "wellness")
predict(glmSchubert, schubertTest, type = "response")
predict(glmSchubert, schubertTest)
#Partitioning the data
monkInTrain <- createDataPartition(y = schubert,
p = .2,
list = FALSE)
#Partitioning the data
schubertInTrain <- createDataPartition(y = schubertDataClean$wellness,
p = .5,
list = FALSE)
#Partitioning the data
#Partitioning the data
schubertInTrain <- createDataPartition(y = glmSchubert$wellness,
p = .2,
list = FALSE)
View(glmSchubert)
#Partitioning the data
#Partitioning the data
schubertInTrain <- createDataPartition(y = schubertDataClean$wellness,
p = .2,
list = FALSE)
# Make your train test based on above indexing
schubertTrain <- glmSchubert[schubertInTrain,]
#Partitioning the data
#create ID column
schubertDataClean$id <- 1:nrow(schubertDataClean)
#use 70% of dataset as training set and 30% as test set
schubertTrain <- schubertDataClean %>% sample_frac(0.70)
schubertTest  <- anti_join(schubertDataClean, schubertTrain, by = 'id')
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
verboseIter = TRUE)
schubertFit <- train(cluster~.,
data = schubertTrain,
method = "glmnet",
trControl = ctrl,
preProc = c("center","scale"))
schubertFit <- train(wellness~.,
data = schubertTrain,
method = "glmnet",
trControl = ctrl,
preProc = c("center","scale"))
schubertClasses <- predict(schubertFit, newdata = schubertTest)
confusionMatrix(schubertClasses, schubertTest$cluster,
positive = NULL,
dnn = c("Prediction", "Reference"),
prevalence = NULL)
schubertImportance <- varImp(object=schubertFit)
plot(schubertImportance)
schubertDataTester <- schubertDataClean %>%
select(id, npvi, degree_entropy, wellness)
#Partitioning the data
#create ID column
schubertDataClean$id <- 1:nrow(schubertDataClean)
schubertDataTester <- schubertDataClean %>%
select(id, npvi, degree_entropy, wellness)
#use 70% of dataset as training set and 30% as test set
schubertTrain <- schubertDataTester %>% sample_frac(0.70)
schubertTest  <- anti_join(schubertDataTester, schubertTrain, by = 'id')
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
verboseIter = TRUE)
schubertFit <- train(wellness~.,
data = schubertTrain,
method = "glmnet",
trControl = ctrl,
preProc = c("center","scale"))
schubertClasses <- predict(schubertFit, newdata = schubertTest)
confusionMatrix(schubertClasses, schubertTest$wellness,
positive = NULL,
dnn = c("Prediction", "Reference"),
prevalence = NULL)
str(schubertDataTester)
schubertDataTester$wellness <- as.factor(schubertDataTester$wellness)
#use 70% of dataset as training set and 30% as test set
schubertTrain <- schubertDataTester %>% sample_frac(0.70)
schubertTest  <- anti_join(schubertDataTester, schubertTrain, by = 'id')
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
verboseIter = TRUE)
schubertFit <- train(wellness~.,
data = schubertTrain,
method = "glmnet",
trControl = ctrl,
preProc = c("center","scale"))
str(schubertDataTester)
#Partitioning the data
#create ID column
schubertDataClean$id <- 1:nrow(schubertDataClean)
schubertDataTester <- schubertDataClean %>%
select(id, npvi, degree_entropy, wellness)
#use 70% of dataset as training set and 30% as test set
schubertTrain <- schubertDataTester %>% sample_frac(0.70)
schubertTest  <- anti_join(schubertDataTester, schubertTrain, by = 'id')
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
verboseIter = TRUE)
schubertFit <- train(wellness~.,
data = schubertTrain,
method = "glmnet",
trControl = ctrl,
preProc = c("center","scale"))
schubertClasses <- predict(schubertFit, newdata = schubertTest)
confusionMatrix(schubertClasses, schubertTest$wellness,
positive = NULL,
dnn = c("Prediction", "Reference"),
prevalence = NULL)
confusionMatrix(schubertClasses, schubertTest$wellness,
positive = NULL,
dnn = c("Prediction", "Reference"),
prevalence = NULL)
confusionMatrix(schubertClasses, schubertTest$wellness,
positive = NULL,
dnn = c("Prediction", "Reference"),
prevalence = NULL)
schubertImportance <- varImp(object=schubertFit)
plot(schubertImportance)
summary(schubertClasses)
confusionMatrix(factor(schubertClasses), schubertTest$wellness,
positive = NULL,
dnn = c("Prediction", "Reference"),
prevalence = NULL)
str(schubertTest)
str(schubertClasses)
schubertClasses <- predict(schubertFit, newdata = schubertTest, type = "response")
schubertClasses <- predict(schubertFit, newdata = schubertTest, type = "raw")
summary(schubertClasses)
confusionMatrix(schubertClasses, schubertTest$wellness,
positive = NULL,
dnn = c("Prediction", "Reference"),
prevalence = NULL)
schubertImportance <- varImp(object=schubertFit)
plot(schubertImportance)
schubertDataClean <- schubert_data %>%
filter(!str_detect(wellness, "uncertain")) %>% #get rid of pieces we aren't certain about his health
select(-NOTES..to.be.deleted., #remove unecessary columns
-completion_date,
-deutsche_num,
-filename) %>%
filter(!str_detect(start_date, "UNKNOWN")) %>% #remove unknowns from the dates
drop_na()
schubert_data <- read.csv("schubert_info3.csv", header=T)
schubertDataClean <- schubert_data %>%
filter(!str_detect(wellness, "uncertain")) %>% #get rid of pieces we aren't certain about his health
select(-NOTES..to.be.deleted., #remove unecessary columns
-completion_date,
-deutsche_num,
-filename) %>%
filter(!str_detect(start_date, "UNKNOWN")) %>% #remove unknowns from the dates
drop_na()
View(schubertDataClean)
View(schubert_data)
names(schubert_data)
library(tidyverse)
str(schubertDataClean)
schubertDataClean$start_date <- as.integer (schubertDataClean$start_date) #convert dates to integers to help with plotting
str(schubertDataClean)
str(schubert_data) #checking data structures
schubertDataClean <- schubert_data %>%
filter(!str_detect(wellness, "uncertain")) %>% #get rid of pieces he wrote when we are uncertain of his health
select(-NOTES..to.be.deleted., #remove unecessary columns
-completion_date,
-deutsche_num,
-filename) %>%
filter(!str_detect(start_date, "UNKNOWN")) %>% #remove unknowns from the dates
drop_na() #omit nas
schubertDataClean$wellness <- if_else(schubertDataClean$wellness == "well", 1, 0) #change "unwell" to 0 and "well" to 1 for binomial analysis
schubertDataClean$start_date <- as.numeric (schubertDataClean$start_date) #convert dates to integers to help with plotting
str(schubertDataClean)
View(schubertDataClean)
schubertDataClean$start_date <- as.integer (schubertDataClean$start_date) #convert dates to integers to help with plotting
str(schubertDataClean)
schubertDataClean %>% #looks like normal disctributions and degree_entropy and intervallic_entropy are positively correlated.
select(degree_entropy, intervallic_entropy, npvi, wellness) %>%
ggpairs()
schubertDataClean %>%
select(degree_entropy, intervallic_entropy, npvi, wellness) %>%
ggpairs()
library(GGally)
schubertDataClean %>%
select(degree_entropy, intervallic_entropy, npvi, wellness) %>%
ggpairs()
###GLM Test for Significant variables
glmTest <- glm(formula = wellness ~ degree_entropy + #npvi and degree_entropy are significant
intervallic_entropy +
npvi,
data = schubertDataClean,
family = binomial(link = "logit"))
summary(glmTest) #npvi and degree_entropy are significant at predicting wellness
glmTest <- glm(formula = wellness ~ degree_entropy + #npvi and degree_entropy are significant
intervallic_entropy +
npvi,
data = schubertDataClean,
family = binomial(link = "logit"))
summary(glmTest) #npvi and degree_entropy are significant at predicting wellness
plot(allEffects(glmTest)) ##to visualize the effect we can see the positive and negative influences of our two significant variables
plot(allEffects(glmTest)) ##to visualize the effect we can see the positive and negative influences of our two significant variables and the relatively flat "intervallic_entropy"
residualPlot(glmTest)
glmSchubert <- glm(formula = wellness ~ degree_entropy + #npvi and degree_entropy are significant
intervallic_entropy,
data = schubertDataClean,
family = binomial(link = "logit"))
anova(glmTest, glmSchubert, test ="Chisq") #evaluating test against model without npvi. Model without npvi is better, so we will proceed with that.
glmTest$aic
glmSchubert$aic #just to further check, and glmSchubert is definitely better.
ggplot(schubertDataClean, aes(x = degree_entropy+npvi, y = wellness)) +
geom_point() +
stat_smooth(method = "glm", method.args = list(family=binomial), se = TRUE)
ggplot(schubertDataClean, aes(start_date, npvi, wellness)) +
geom_rect(aes(NULL, NULL,
xmin=start_date - .5 ,xmax=start_date +.5,
ymin=min(npvi), ymax=max(npvi),
fill=wellness)) +
geom_point() +
geom_smooth()
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
geom_rect(aes(NULL, NULL,
xmin=start_date - .5 , xmax=start_date +.5,
ymin=min(degree_entropy), ymax=max(degree_entropy),
fill=wellness
)) +
geom_point() +
geom_smooth()
ggplot(schubertDataClean, aes(start_date, npvi, wellness)) +
geom_rect(aes(NULL, NULL,
xmin=start_date - .5 ,xmax=start_date +.5,
ymin=min(npvi), ymax=max(npvi),
fill=wellness)) +
geom_point() +
geom_smooth()
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
geom_rect(aes(NULL, NULL,
xmin=start_date - .5 , xmax=start_date +.5,
ymin=min(degree_entropy), ymax=max(degree_entropy),
fill=wellness
)) +
geom_point() +
geom_smooth()
library(effects)
setwd("/Users/connordavis/Desktop/projects/gitHub/schubertWellness")
setwd("/Users/connordavis/Desktop/projects/gitHub/schubertWellness")
setwd("/Users/connordavis/Desktop/projects/gitHub/schubertWellness")
setwd("/Users/connordavis/Desktop/projects/gitHub/schubertWellness")
setwd("/Users/connordavis/Desktop/projects/gitHub/schubertWellness/")
setwd("/Users/connordavis/Desktop/projects/gitHub/schubertWellness/")
schubert_data <- read.csv("schubertData.csv", header=T)
library(dplyr)
library(corrplot)
library(car)
library(psych)
library(aod)
###cleaning it up
str(schubert_data)
schubert_data$start_date <- as.character(schubert_data$start_date) #convert to date
subsetted_schubert <- filter(schubert_data, start_date > 0) #remove nas and oddities
subsetted_schubert <- filter(schubert_data, wellness != "uncertain") #remove uncertain composition dates
subsetted_schubert <- drop_na(subsetted_schubert) #remove na subsetted_schubert <- as.factor(subsetted_schubert$wellness)
subsetted_schubert$wellness <- as_factor(subsetted_schubert$wellness)
#subsetted_schubert$wellness <- droplevels(subsetted_schubert$wellness)
#plot(subsetted_schubert$npvi ~ subsetted_schubert$start_date)
linear_model <- lm(subsetted_schubert$npvi ~ subsetted_schubert$start_date)
abline(linear_model, col="Red")
summary(linear_model)
afterUnwell <- filter(subsetted_schubert, start_date > 1822)
beforeUnwell <- filter(subsetted_schubert, start_date <= 1822)
model <- aov(before$intervallic_entropy ~ after$intervallic_entropy)
library(sm)
boxplot(subsetted_schubert$intervallic_entropy ~ subsetted_schubert$wellness) #checking for differneces in entropy
sm.density.compare(subsetted_schubert$intervallic_entropy, subsetted_schubert$wellness, col=c("black","black"), xlab="intervallic_entropy", h=.7) #distribution looks normal
legend("topleft", levels(subsetted_schubert$wellness),lty=(1:nlevels(subsetted_schubert$wellness)))
sm.density.compare(subsetted_schubert$degree_entropy, subsetted_schubert$wellness, col=c("black","black"), xlab="degree_entropy", h=.7) #distribution looks normal
legend("topleft", levels(subsetted_schubert$wellness),lty=(1:nlevels(subsetted_schubert$wellness)))
sm.density.compare(subsetted_schubert$npvi, subsetted_schubert$wellness, col=c("black","black"), xlab="npvi", h=2) #looks normal
legend("topleft", levels(subsetted_schubert$wellness),lty=(1:nlevels(subsetted_schubert$wellness)))
#---
setwd("/Users/connordavis/Desktop/giHub/schubertWellness")
#---
setwd("/Users/connordavis/Desktop/gitHub/schubertWellness")
#---
setwd("/Users/connordavis/Desktop/projects/schubert/")
schubert_data <- read.csv("schubert_info3.csv", header=T)
library(tidyverse)
library(GGally)
library(effects) #for plotting parameter effects
str(schubert_data)
schubertDataClean <- schubert_data %>%
filter(!str_detect(wellness, "uncertain")) %>% #get rid of pieces we aren't certain about his health
select(-NOTES..to.be.deleted., #remove unecessary columns
-completion_date,
-deutsche_num,
-filename) %>%
filter(!str_detect(start_date, "UNKNOWN")) %>% #remove unknowns from the dates
drop_na()
schubertDataClean$wellness <- if_else(schubertDataClean$wellness == "well", 1, 0)
schubertDataClean$start_date <- as.integer(schubertDataClean$start_date)
schubertDataClean %>% #looks like normal disctributions and degree_entropy and intervallic_entropy are positively correlated.
select(degree_entropy, intervallic_entropy, npvi, wellness) %>%
ggpairs()
###GLM Test for Significant variables
glmTest <- glm(formula = wellness ~ degree_entropy + #npvi and degree_entropy are significant
intervallic_entropy +
npvi,
data = schubertDataClean,
family = binomial(link = "logit"))
summary(glmTest) #npvi and degree_entropy are significant at predicting wellness
plot(allEffects(glmTest)) ##to visualize the effect we can see the positive and negative influences of our two significant variables
glmSchubert <- glm(formula = wellness ~ degree_entropy + #npvi and degree_entropy are significant
intervallic_entropy,
data = schubertDataClean,
family = binomial(link = "logit"))
anova(glmTest, glmSchubert, test ="Chisq") #evaluating test against model without npvi. Model without npvi is better, so we will proceed with that. Note chi-squared.
glmTest$aic
glmSchubert$aic #just to further check, and glmSchubert is definitely better.
ggplot(schubertDataClean, aes(x = degree_entropy+npvi, y = wellness)) +
geom_point() +
stat_smooth(method = "glm", method.args = list(family=binomial), se = TRUE)
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
geom_rect(aes(NULL, NULL,
xmin=start_date - .5 , xmax=start_date +.5,
ymin=min(degree_entropy), ymax=max(degree_entropy),
fill=wellness
)) +
geom_point() +
geom_smooth()
ggplot(schubertDataClean, aes(start_date, npvi, wellness)) +
geom_rect(aes(NULL, NULL,
xmin=start_date - .5 ,xmax=start_date +.5,
ymin=min(npvi), ymax=max(npvi),
fill=wellness)) +
geom_point() +
geom_smooth()
setwd("/Users/connordavis/Desktop/gitHub/schubertWellness/")
schubert_data <- read.csv("schubertData.csv", header=T)
#---
setwd("/Users/connordavis/Documents/GitHub/schubertWellness/")
schubert_data <- read.csv("schubertData.csv", header=T)
library(tidyverse)
library(GGally)
library(effects) #for plotting parameter effects
str(schubert_data)
schubertDataClean <- schubert_data %>%
filter(!str_detect(wellness, "uncertain")) %>% #get rid of pieces we aren't certain about his health
select(-NOTES..to.be.deleted., #remove unecessary columns
-completion_date,
-deutsche_num,
-filename) %>%
filter(!str_detect(start_date, "UNKNOWN")) %>% #remove unknowns from the dates
drop_na()
schubertDataClean$wellness <- if_else(schubertDataClean$wellness == "well", 1, 0)
schubertDataClean$start_date <- as.integer(schubertDataClean$start_date)
schubertDataClean %>% #looks like normal disctributions and degree_entropy and intervallic_entropy are positively correlated.
select(degree_entropy, intervallic_entropy, npvi, wellness) %>%
ggpairs()
###GLM Test for Significant variables
glmTest <- glm(formula = wellness ~ degree_entropy + #npvi and degree_entropy are significant
intervallic_entropy +
npvi,
data = schubertDataClean,
family = binomial(link = "logit"))
summary(glmTest) #npvi and degree_entropy are significant at predicting wellness
plot(allEffects(glmTest)) ##to visualize the effect we can see the positive and negative influences of our two significant variables
glmSchubert <- glm(formula = wellness ~ degree_entropy + #npvi and degree_entropy are significant
intervallic_entropy,
data = schubertDataClean,
family = binomial(link = "logit"))
anova(glmTest, glmSchubert, test ="Chisq") #evaluating test against model without npvi. Model without npvi is better, so we will proceed with that. Note chi-squared.
glmTest$aic
glmSchubert$aic #just to further check, and glmSchubert is definitely better.
ggplot(schubertDataClean, aes(x = degree_entropy+npvi, y = wellness)) +
geom_point() +
stat_smooth(method = "glm", method.args = list(family=binomial), se = TRUE)
ggplot(schubertDataClean, aes(start_date, degree_entropy, wellness)) +
geom_rect(aes(NULL, NULL,
xmin=start_date - .5 , xmax=start_date +.5,
ymin=min(degree_entropy), ymax=max(degree_entropy),
fill=wellness
)) +
geom_point() +
geom_smooth()
ggplot(schubertDataClean, aes(start_date, npvi, wellness)) +
geom_rect(aes(NULL, NULL,
xmin=start_date - .5 ,xmax=start_date +.5,
ymin=min(npvi), ymax=max(npvi),
fill=wellness)) +
geom_point() +
geom_smooth()
